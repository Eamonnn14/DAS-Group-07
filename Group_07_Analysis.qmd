---
title: "Behind the Curtain: Statistical Insights into Movie Success"
author: "Cheng Tang, Mingcan Wang, Yiang Liang, Yuxuan Zhao, Zilu Wang"
number-sections: true
format: 
  html:
    embed-resources: true
    code-tools: true
  pdf: 
    fig-pos: "H"
editor_options: 
  chunk_output_type: console
execute:
  echo: false
  eval: true
  warning: false
  message: false
---

# Introduction

In the evolving landscape of cinematic entertainment, the question of what factors lead a film to be favorably received by audiences has intrigued producers, directors, and marketers alike. This project, titled "Behind the Curtain: Statistical Insights into Movie Success" embarks on a statistical journey to decipher the complex dynamics between various film attributes and their resulting viewer ratings, specifically focusing on the critical threshold of a rating above 7, often considered a benchmark for success in the industry.

The inception of this analysis is rooted in the premise that a film's length, budget, viewer engagement (measured through votes), and genre hold significant sway over its overall reception. Traditionally, the entertainment industry has relied on anecdotal evidence or isolated case studies to gauge the potential success of film projects. However, this project leverages a Generalized Linear Model (GLM) to evaluate these factors, offering a more empirical basis for understanding cinematic success.

The data set comprises diverse films spanning various years, genres, and production scales, enabling a comprehensive analysis that transcends specific market trends or cultural biases. By employing a generalized linear regression framework, we aim to predict the likelihood of a film achieving a rating above 7, transforming subjective notions of quality and appeal into quantifiable probabilities. The selection of variables such as 'length', 'budget', and 'votes' is predicated on the hypothesis that these factors collectively encapsulate elements of narrative compactness, production quality, and audience engagement—each a potential predictor of a film's rating.

As we navigate through this project, the goal is to distill actionable insights that can guide filmmakers and studios in crafting content that resonates with viewers. Beyond its immediate application, this study contributes to the broader discourse on the quantification of artistic and entertainment value, marking a confluence of creativity and analytics.

```{r}
#| label: libraries
library(ggplot2)
library(tidyverse)
library(gt)
library(patchwork)
library(gridExtra)
library(moderndive)
library(GGally)
library(corrplot)
library(caret)
library(pROC)
```

```{r}
#| label: data
data <- read.csv("/Users/ziluwang/Documents/GitHub/DAS-Project2-Group7/dataset07.csv", na.strings = 'NA')
```

```{r}
# Check for missing values
#colSums(is.na(data))
```

```{r}
# Data wrangling
# Replace missing values in length with median
data$length[is.na(data$length)] <- median(data$length, na.rm = TRUE)
# Creating a new binary variable based on rating is greater than 7 or not
data$above_7 <- ifelse(data$rating > 7, 1, 0)
data$above_7 <- factor(data$above_7, levels = c(0, 1))
# Change 'genre' from character to factor
data$genre <- factor(data$genre)
```

# Methodology

The methodology of the project involves a systematic approach to understanding the factors contributing to movie success, as measured by audience ratings. Initially, the data is cleansed and pre-processed, which includes handling missing values and transforming skewed distributions through log transformations for variables such as film length and votes to achieve distributions closer to normal. Subsequently, a binary variable is created to distinguish films based on whether they have achieved a rating above 7.

An extensive Exploratory Data Analysis (EDA) is conducted to gain deeper insights into underlying patterns and relationships. This includes examining the distributions of key variables, identifying outliers, and assessing correlations.

The analysis then employs a Generalized Linear Model (GLM), specifically logistic regression, to examine the influence of various film attributes—namely, length, budget, viewer engagement (votes), and genre—on the likelihood of a film receiving a rating above 7, which is considered indicative of success. The model's predictive power and fit are assessed through accuracy, sensitivity, specificity, and the Area Under the Receiver Operating Characteristic (ROC) Curve (AUC) metrics.

To fine-tune the model, a series of candidate thresholds for classification are evaluated to identify the optimal balance between sensitivity and specificity. This involves calculating performance metrics across different threshold values and selecting the one that provides the best compromise according to the project's objectives.

The methodology also encompasses residual analysis to evaluate the model's assumptions and the fit to the data, ensuring the reliability and validity of the findings. Finally, based on the insights gained from the EDA and GLM analysis, strategic recommendations are formulated to guide filmmakers and producers in aligning their projects with the attributes associated with higher-rated films.

# Exploratory Data Anlaysis

## Statistical Summary

```{r}
# Load necessary libraries
library(tidyverse)
library(gt)

# Define the specific variables for the summary
selected_vars <- c("year", "length", "budget", "votes", "rating")

# Generate a statistical summary for the selected numeric columns in the dataset
data_summary <- data %>%
  select(all_of(selected_vars)) %>%
  summarise(across(everything(), list(
    Mean = ~mean(.x, na.rm = TRUE),
    SD = ~sd(.x, na.rm = TRUE),
    Median = ~median(.x, na.rm = TRUE),
    IQR = ~IQR(.x, na.rm = TRUE),
    Min = ~min(.x, na.rm = TRUE),
    Max = ~max(.x, na.rm = TRUE)
  ), .names = "{.col}_{.fn}")) %>% # Ensure unique column names for pivoting
  pivot_longer(cols = everything(), names_to = "summary_metric", values_to = "value") %>% # Convert to long format for easier management
  separate(summary_metric, into = c("variable", "statistic"), sep = "_") %>% # Separate variable and statistic
  pivot_wider(names_from = statistic, values_from = value) # Pivot wider for final format

# Convert the summary into a table using gt
data_summary_table <- gt(data_summary) %>%
  tab_header(
    title = "Statistical Summary of Numerical Variables"
  ) %>%
  cols_label(
    variable = "Variable",
    Mean = "Mean",
    SD = "Standard Deviation",
    Median = "Median",
    IQR = "Interquartile Range",
    Min = "Minimum",
    Max = "Maximum"
  )

# Print the table
data_summary_table

```

```{r}

# Define the specific variables for the summary
categorical_vars <- c("genre", "above_7")

# Generate frequency tables for the selected categorical columns in the dataset
cat_summary <- data %>%
  select(all_of(categorical_vars)) %>%
  map_df(~data_frame(
    variable = deparse(substitute(.x)),
    n_levels = n_distinct(.x),
    levels = list(levels(factor(.x))),
    freq = list(table(.x))
  ), .id = "variable")

# Tidy up frequency tables for presentation
cat_summary$levels <- sapply(cat_summary$levels, toString)
cat_summary$freq <- sapply(cat_summary$freq, toString)

# Convert the summary into a table using gt and add a tab header
cat_summary_table <- gt(cat_summary) %>%
  tab_header(
    title = "Statistical Summary of Categorical Variables"
  )

# Print the table
cat_summary_table

```

```{r}
# Apply log transformation to length and votes
data$length_log <- log1p(data$length)
data$votes_log <- log1p(data$votes)
```

## Outliers

```{r}
# Calculate the proportion of outliers for each numeric variable

# Defining the function to calculate the proportion of outliers
calculate_outliers <- function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  num_outliers <- sum(x < lower_bound | x > upper_bound, na.rm = TRUE)
  total_values <- sum(!is.na(x))
  proportion_outliers <- num_outliers / total_values
  return(proportion_outliers)
}

# Apply the function only to 'length', 'budget', and 'votes' columns
selected_columns <- c("length", "budget", "votes")
outlier_proportions <- sapply(data[selected_columns], calculate_outliers)

# Convert the proportions to a data frame for easier reading
outlier_table <- as.data.frame(t(outlier_proportions), row.names = "Proportion of Outliers")
outlier_table
```

```{r}
# # Calculate the proportion of outliers for each numeric variable after log transformation
# 
# # Apply the function only to 'length_log', and 'votes_log' columns
# selected_columns <- c("length_log", "votes_log")
# outlier_proportions <- sapply(data[selected_columns], calculate_outliers)
# 
# # Convert the proportions to a data frame for easier reading
# outlier_table <- as.data.frame(t(outlier_proportions), row.names = "Proportion of Outliers")
# outlier_table
```

```{r}
# calculate_and_print_outliers <- function(x) {
#   Q1 <- quantile(x, 0.25, na.rm = TRUE)
#   Q3 <- quantile(x, 0.75, na.rm = TRUE)
#   IQR <- Q3 - Q1
#   lower_bound <- Q1 - 1.5 * IQR
#   upper_bound <- Q3 + 1.5 * IQR
#   outliers <- x[x < lower_bound | x > upper_bound]
#   return(outliers)
# }
# 
# # Apply the modified function only to 'length', 'budget', and 'votes' columns
# selected_columns <- c("length", "budget", "votes")
# list_outliers <- lapply(data[selected_columns], calculate_and_print_outliers)
# 
# # Print the actual outliers for each variable
# list_outliers
```

## Visualisation

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)

# List of numeric variables and their respective titles and x-axis labels
numeric_vars <- c("year", "length", "budget", "votes")
titles <- c("Distribution of Years", "Distribution of Film Lengths",
            "Distribution of Budgets", "Distribution of Votes")
x_labels <- c("Year", "Length (minutes)", "Budget (millions $)", "Votes")

# Loop through numeric variables to create histograms using ggplot2
plot_list <- list()  # Initialize an empty list to store plots

for (i in 1:length(numeric_vars)) {
  plot_list[[i]] <- ggplot(data, aes_string(x = numeric_vars[i])) + 
    geom_histogram(color = "white") +
    labs(title = titles[i], x = x_labels[i], y = "Frequency") +
    theme_minimal()
}

# Display the plots
gridExtra::grid.arrange(grobs = plot_list, ncol = 2)
```

```{r}
# List of numeric variables
numeric_vars <- c("year", "length_log", "budget", "votes_log")

# Titles and x-axis labels for the histograms
titles <- c("Distribution of Years", "Distribution of log(Film Lengths)",
            "Distribution of Budgets", "Distribution of log(Votes)")
x_labels <- c("Year", "Log(length)", "Budget (millions $)", "Votes", "Rating")

# Loop through numeric variables to create histograms using ggplot2
plot_list <- list()  # Initialize an empty list to store plots

for (i in 1:length(numeric_vars)) {
  plot_list[[i]] <- ggplot(data, aes_string(x = numeric_vars[i])) + 
    geom_histogram(color = "white") +
    labs(title = titles[i], x = x_labels[i], y = "Frequency") +
    theme_minimal()
}

# Display the plots
gridExtra::grid.arrange(grobs = plot_list, ncol = 2)
```

```{r}
numeric_vars <- c("year", "length", "budget", "votes")
# Set up an empty list to store the ggplot objects
plot_list <- list()

# Loop through numeric variables to create boxplots using ggplot2
for (i in 1:length(numeric_vars)) {
  var <- numeric_vars[i]
  plot_list[[i]] <- ggplot(data, aes_string(y = var)) + 
    geom_boxplot(color = "black") +
    labs(title = paste("Distribution of", var), ylab = var, x = "") +
    theme_minimal() +
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())  # Hide x-axis text and ticks
}

# Print the plots
library(gridExtra)
grid.arrange(grobs = plot_list, ncol = 2)
```

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)

# Bar plot for genre
genre_plot <- ggplot(data, aes(x = genre)) +
  geom_bar(color = "black") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +  # Rotate genre labels
  labs(title = "Film Counts by Genre", x = "Genre", y = "Count")

# Bar plot for above_7
above7_plot <- ggplot(data, aes(x = as.factor(above_7))) +  # Ensure above_7 is treated as a factor
  geom_bar(color = "black") +
  theme_minimal() +
  labs(title = "Film Counts by Above 7", x = "Above 7", y = "Count")

# Print the plots side by side
library(gridExtra)
grid.arrange(genre_plot, above7_plot, ncol = 2)

```

```{r}
numeric_data <- dplyr::select(data, -film_id, -genre, -above_7, -rating, -year)
ggpairs(numeric_data) + 
  ggtitle("Pairplot of Numeric Variables")
```


```{r}
# Load necessary libraries
library(ggplot2)

# List of numeric variables for plotting
numeric_vars <- c("year", "length", "budget", "votes")

# Set up an empty list to store the ggplot objects
plot_list <- list()

# Loop through numeric variables to create boxplots using ggplot2
for (i in 1:length(numeric_vars)) {
  var <- numeric_vars[i]
  plot_list[[i]] <- ggplot(data, aes(x = as.factor(above_7), y = .data[[var]])) + 
    geom_boxplot(color = "black") +
    labs(title = paste(var, "vs. Above 7"), x = "Above 7", y = var) +
    theme_minimal()
}

# Print the plots
library(gridExtra)
grid.arrange(grobs = plot_list, ncol = 2)

```

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(scales)  # Ensure this is loaded for the percent formatter

# Convert the data into a suitable format for ggplot
data_long <- data %>%
  group_by(genre, above_7) %>%
  summarise(count = n(), .groups = 'drop') %>%
  mutate(freq = count / sum(count)) %>%
  ungroup() %>%
  mutate(above_7 = as.factor(above_7), # Ensure above_7 is treated as a factor
         genre = factor(genre, levels = unique(genre)))  # Ensure genres are ordered as they appear

# Create the 100% stacked bar plot with specific colors for above_7 variable
ggplot(data_long, aes(x = genre, y = freq, fill = above_7)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_fill_manual(values = c("0" = "lightgrey", "1" = "darkgrey")) +  # Set custom fill colors
  scale_y_continuous(labels = percent) +  # Convert y-axis to percentage
  labs(title = "Proportion of Ratings Above 7 by Genre",
       x = "Genre",
       y = "Proportion",
       fill = "Rating Above 7") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels


```

```{r}
ggplot(data, aes(x = genre, y = length)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Boxplot of Movie Length by Genre",
       x = "Genre", y = "Length (minutes)")

ggplot(data, aes(x = genre, y = budget)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Boxplot of Movie Budget by Genre",
       x = "Genre", y = "Budget (millions $)")

ggplot(data, aes(x = genre, y = votes_log)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Boxplot of Log(Votes) by Genre",
       x = "Genre", y = "Log(Votes)")
```

```{r}
# Prepare the data by selecting relevant variables and convert 'above_7' to a factor
data_for_plot <- data %>%
  dplyr::select(year, budget, length_log, votes_log, above_7) %>%
  mutate(above_7 = factor(above_7, labels = c("Below 7", "Above 7")))

# Create the parallel coordinates plot with increased line transparency
ggparcoord(data = data_for_plot,
           columns = c(1, 2, 3, 4), # Indices for year, budget, length_log, votes_log
           groupColumn = "above_7", # Use 'above_7' to differentiate lines
           scale = "uniminmax", # This scales each variable to [0,1]
           title = "Parallel Coordinates Plot for Movie Data",
           alphaLines = 0.1) + # Increase transparency by lowering alpha value
  scale_color_manual(values = c("Below 7" = "red", "Above 7" = "blue")) + # Custom colors
  theme_minimal() +
  labs(color = "Rating Above 7") # Update legend title

```

## EDA Findings

In the exploratory data analysis, we observed distinct patterns within the film data set. The length of films is right-skewed, with most under 100 minutes, but exceptions extending up to 399 minutes. Conversely, budgets appear nearly normally distributed, indicating diverse financial investments across films. The 'votes' distribution is significantly right-skewed, highlighting a disparity in viewer engagement.

After log transformations, the distributions of 'length' and 'votes' approached closer to normality but still exhibited skewness. The data set predominantly features action, drama, and comedy genres, with fewer romantic and short films. Notably, only 35% of movies are rated above 7.

There is a medium positive correlation between log-transformed votes and length, suggesting films of longer duration may engage viewers more. Budget analyses indicate movies rated above 7 typically have higher budgets. Genre-wise, documentaries stand out with a highest proportion of high-rated films, whereas romance, drama, and action genres show fewer films surpassing the rating threshold. Short films and animations are generally shorter, whereas romance tends to be longer. Despite uniform budget distribution across genres, action and documentaries exhibit slightly higher budgets. Lastly, romance genre films receive the most votes, while short films receive the fewest, indicating varying audience engagement levels by genre.

# Formal Analysis

```{r}
# Remove unwanted columns from dataframe
data_clean <- dplyr::select(data, -film_id, -rating)
```

```{r}
# split train and test dataset 
set.seed(123)  # for reproducibility
index <- createDataPartition(data_clean$above_7, p = .70, list = FALSE)
train_data <- data_clean[index, ]
test_data <- data_clean[-index, ]
```

```{r}
# Define Full Model
glm_model_full <- glm(above_7 ~ year + length + budget + votes + genre, 
                      family = binomial, data = train_data)
```

```{r}
# Define thresholds evaluation method
evaluate_thresholds <- function(model, test_data, thresholds) {
  results <- data.frame(Threshold = thresholds, Accuracy = NA, Sensitivity = NA, Specificity = NA, AUC = NA)
  
  # Predict probabilities on the test data
  predictions <- predict(model, test_data, type = "response")
  roc_response <- roc(response = test_data$above_7, predictor = predictions)
  auc_value <- auc(roc_response)
  
  for (i in seq_along(thresholds)) {
    threshold <- thresholds[i]
    predicted_class <- ifelse(predictions > threshold, 1, 0)
    conf_matrix <- confusionMatrix(factor(predicted_class), factor(test_data$above_7))
    
    results[i, "Accuracy"] <- conf_matrix$overall['Accuracy']
    results[i, "Sensitivity"] <- conf_matrix$byClass['Sensitivity']
    results[i, "Specificity"] <- conf_matrix$byClass['Specificity']
    results[i, "AUC"] = auc_value  # AUC remains constant for different thresholds
  }
  
  return(results)
}
```

## Find Optimal Threshold

In determining the optimal classification threshold for our logistic regression model, especially when faced with an imbalanced target variable, a systematic approach is adopted. A range of potential thresholds is evaluated to assess their impact on key performance metrics: Accuracy, Sensitivity, and Specificity. This process allows for the identification of a threshold that strikes the best balance between correctly identifying true positives and true negatives. The objective is to enhance the model's predictive power and ensure a more informed, context-specific application, particularly important in scenarios where accurate classification holds significant consequences. This methodology ensures that the chosen threshold aligns with the specific needs and goals of the analysis, addressing the challenges posed by an imbalanced dataset.

```{r}
# Define a series of candidate thresholds
candidate_thresholds <- seq(0.1, 0.9, by = 0.05)

threshold_evaluation_results <- evaluate_thresholds(glm_model_full, test_data, candidate_thresholds)

ggplot(threshold_evaluation_results, aes(x = Threshold)) +
  geom_line(aes(y = Accuracy, colour = "Accuracy"), size = 1.2) +
  geom_line(aes(y = Sensitivity, colour = "Sensitivity"), size = 1.2) +
  geom_line(aes(y = Specificity, colour = "Specificity"), size = 1.2) +
  scale_colour_manual("", 
                      breaks = c("Accuracy", "Sensitivity", "Specificity"),
                      values = c("Accuracy" = "#1b9e77", "Sensitivity" = "#d95f02", "Specificity" = "#7570b3")) +
  labs(title = "Model Performance Across Different Thresholds",
       y = "Metric Value",
       x = "Threshold") +
  theme_minimal() +
  theme(legend.position = "right")
```

The classification threshold of 0.32, as observed from the plot, optimally balances accuracy, sensitivity, and specificity. This threshold reflects a strategic compromise, enhancing the model's ability to correctly identify films rated above and below 7, without heavily sacrificing one metric for another.

## Model Building

```{r echo = TRUE}
# Full model
glm_model_full <- glm(above_7 ~ year + length + budget + votes + genre, 
                      family = binomial, data = train_data)
# Full Model with Log Transformation
glm_model_log <- glm(above_7 ~ year + length_log + budget + votes_log + genre, 
                     family = binomial, data = train_data)

# Model without Year
glm_model_no_year <- glm(above_7 ~ length_log + budget + votes_log + genre, 
                        family = binomial, data = train_data)

# Model without Year and Votes_log
glm_model_no_year_votes <- glm(above_7 ~ length_log + budget + genre, 
                               family = binomial, data = train_data)
# Model without Year and Length_log
glm_model_no_year_length <- glm(above_7 ~ votes_log + budget + genre, 
                               family = binomial, data = train_data)
```

In this project, the modeling principle involved constructing and refining a series of logistic regression models to identify key factors influencing a movie's success, defined as achieving a rating above 7. The full model included all variables (except ID), offering a comprehensive baseline for analysis.

Subsequent models were developed by applying log transformation and removing variables based on their statistical significance, assessed through p-values, and their impact on the model's overall performance. This iterative process aimed to streamline the model, removing less impactful variables while observing changes in performance metrics like accuracy, sensitivity, specificity, and the Area Under the Curve (AUC).

## Model Selection

```{r}
# Define evaluate_model function to return metrics
evaluate_model <- function(model, test_data) {
  predictions <- predict(model, test_data, type = "response")
  predicted_class <- ifelse(predictions > 0.32, 1, 0)  # Classification threshold at 0.32
  conf_matrix <- confusionMatrix(factor(predicted_class), factor(test_data$above_7))
  roc_response <- roc(response = test_data$above_7, predictor = predictions)
  
  # Compile performance metrics
  metrics <- list(
    Accuracy = conf_matrix$overall['Accuracy'],
    Sensitivity = conf_matrix$byClass['Sensitivity'],
    Specificity = conf_matrix$byClass['Specificity'],
    AUC = auc(roc_response), 
    BIC = BIC(model)
  )
  
  return(metrics)  # Return metrics for storage
}
# Assuming your models are named and your test_data is ready
# Store metrics in a structured way
metrics_list <- list()
metrics_list[['Model 1']] <- evaluate_model(glm_model_full, test_data)
metrics_list[['Model 2']] <- evaluate_model(glm_model_log, test_data)
metrics_list[['Model 3']] <- evaluate_model(glm_model_no_year, test_data)
metrics_list[['Model 4']] <- evaluate_model(glm_model_no_year_votes, test_data)
metrics_list[['Model 5']] <- evaluate_model(glm_model_no_year_length, test_data)


# Compile metrics into a summary table
summary_table <- sapply(metrics_list, function(x) sapply(x, function(y) y))  # Collect metrics
summary_table <- t(summary_table)  # Transpose to make rows correspond to models
summary_table <- round(summary_table, 4)  # Round for readability

# Setting the column names if they are not automatically set
model_descriptions <- c(
    "year + length + budget + votes + genre",
    "year + length_log + budget + votes_log + genre",
    "length_log + budget + votes_log + genre",
    "length_log + budget + genre",
    "votes_log + budget + genre"
)
#summary_table$Variables <- model_descriptions
colnames(summary_table) <- c("Accuracy", "Sensitivity", "Specificity", "AUC", "BIC")

summary_table <- as.data.frame(summary_table)
summary_table$Variables <- model_descriptions
summary_table <- summary_table[, c('Variables', setdiff(names(summary_table), 'Variables'))]

# Print the summary table
summary_table
```

Model 4, featuring log-transformed film length, budget, and genre, is selected as the optimal model due to its superior balance of performance and simplicity. Exhibiting the highest specificity (0.9008) among the evaluated models, it effectively identifies films not surpassing the rating threshold. Its accuracy (0.8937) and sensitivity (0.8898) are commendable, with an AUC value of 0.9405 indicating strong discriminative power. The reduced Bayesian Information Criterion (BIC) of 941.4027 suggests efficient modeling with fewer predictors, underlining its effectiveness without undue complexity.

## Model Interpretation

```{r}
summary(glm_model_no_year_votes)
```

1.  **Length of Movies (length_log)**: There is a significant negative relationship between the log-transformed length of movies and their likelihood of being rated above 7. This suggests that longer movies are less likely to receive high ratings, potentially indicating viewer preferences for shorter films or perhaps an association with certain film types or genres that are longer but less popular.

2.  **Budget (budget)**: The budget of a movie shows a significant positive association with the likelihood of being rated above 7. This might imply that higher-budget movies, which can afford better production quality, actors, and marketing, are more likely to be well-received by audiences.

3.  **Genre**:

    -   **Animation and Drama**: Compared to the baseline genre (action), animation and drama films are significantly less likely to be rated above 7.
    -   **Short, Comedy, and Documentary**: These genres show higher probability of receiving high ratings compared to action, suggesting they are generally well-received or cater to specific audience segments that rate them favorably.
    -   **Romance**: This genre do not show significant effects, possibly due to a smaller sample size, less variation in ratings, or other model limitations.

## Residual Analysis

```{r}
# residuals <- resid(glm_model_no_year, type = "deviance")
# # Plotting deviance residuals against predictors
# par(mfrow = c(2, 2))  # Set up the plotting area
# plot(train_data$length_log, residuals, xlab = "log(Length)", ylab = "Deviance Residuals")
# plot(train_data$budget, residuals, xlab = "Budget", ylab = "Deviance Residuals")
# # For a categorical variable like genre, boxplots can be useful
# boxplot(residuals ~ train_data$genre, ylab = "Deviance Residuals", xlab = "Genre")
```

```{r}
# Assuming your model is named glm_model
fitted_model <- glm(above_7 ~ length_log + budget + genre, family = binomial, data = train_data)
dev_res <- resid(fitted_model, type = "deviance")
plot(dev_res, ylab = "Deviance Residuals", main = "Plot of Deviance Residuals")
abline(h = 0, col = "red")  # Reference line at 0
```

```{r}
qqnorm(dev_res)
qqline(dev_res, col = "red")
```

The residual analysis indicates that the model is reasonably well-fitted, with residuals displaying no systematic bias and consistent spread. However, the presence of outliers and deviations from normality in the tails, as shown in the Q-Q plot, suggest that the data may have more extreme values than a standard normal distribution would predict. This implies that while the model generally captures the data's central tendency, it may need refinement to better accommodate the extreme values or outliers observed.

# Conclusion

Our analysis reveals that film length, budget, viewer votes, and genre significantly impact movie ratings. Specifically, shorter films, higher budgets, and increased viewer engagement (as measured by votes) are positively correlated with ratings above 7, underscoring the importance of narrative conciseness, financial investment, and audience interaction in cinematic success. Among genres, documentaries stand out for their high proportion of well-rated films, while action, drama, and romance show varying levels of success. These insights underscore a multifaceted approach to predicting film success, suggesting that filmmakers can enhance audience reception by strategically balancing these key factors within the creative and production processes.

# Discussion

## Practical Implications

-   Filmmakers and producers can leverage insights from this model, particularly around film length, budget, and targeted genre, to optimize their projects for higher audience ratings.
-   The significant predictors offer a blueprint for aligning movie projects with characteristics correlated with success, though considerations of artistic intent and narrative integrity remain paramount.

## Further Research

-   The disparities observed in genre impacts necessitate deeper investigation, potentially requiring broader datasets to ensure nuanced understandings.
-   Future research should address the data limitations, particularly for underrepresented genres, and explore external factors beyond the scope of the current model to provide a more comprehensive understanding.
